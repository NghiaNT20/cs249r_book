---
bibliography: introduction.bib
---

# Introduction {#sec-introduction}

![_DALLÂ·E 3 Prompt: A detailed, rectangular, flat 2D illustration depicting a roadmap of a book's chapters on machine learning systems, set on a crisp, clean white background. The image features a winding road traveling through various symbolic landmarks. Each landmark represents a chapter topic: Introduction, ML Systems, Deep Learning, AI Workflow, Data Engineering, AI Frameworks, AI Training, Efficient AI, Model Optimizations, AI Acceleration, Benchmarking AI, On-Device Learning, Embedded AIOps, Security & Privacy, Responsible AI, Sustainable AI, AI for Good, Robust AI, Generative AI. The style is clean, modern, and flat, suitable for a technical book, with each landmark clearly labeled with its chapter title._](images/png/cover_introduction.png)

## Overview

In the early 1990s, [Mark Weiser](https://en.wikipedia.org/wiki/Mark_Weiser), a pioneering computer scientist, introduced the world to a revolutionary concept that would forever change how we interact with technology. This was succintly captured in the paper he wrote on "The Computer for the 21st Century" (@fig-ubiqutous). He envisioned a future where computing would be seamlessly integrated into our environments, becoming an invisible, integral part of daily life. This vision, which he termed "ubiquitous computing," promised a world where technology would serve us without demanding our constant attention or interaction. Fast forward to today, and we find ourselves on the cusp of realizing Weiser's vision, thanks to the advent and proliferation of machine learning systems.

![Ubiqutous computing.](images/png/21st_computer.png){#fig-ubiqutous width=50%}

In the vision of ubiquitous computing [@weiser1991computer], the integration of processors into everyday objects is just one aspect of a larger paradigm shift. The true essence of this vision lies in creating an intelligent environment that can anticipate our needs and act on our behalf, enhancing our experiences without requiring explicit commands. To achieve this level of pervasive intelligence, it is crucial to develop and deploy machine learning systems that span the entire ecosystem, from the cloud to the edge and even to the tiniest IoT devices.

By distributing machine learning capabilities across the "computing continuum," from cloud to edge to embedded systems that surround us, we can harness the strengths of each layer while mitigating their limitations. The cloud, with its vast computational resources and storage capacity, is ideal for training complex models on large datasets and performing resource-intensive tasks. Edge devices, such as gateways and smartphones, can process data locally, enabling faster response times, improved privacy, and reduced bandwidth requirements. Finally, the tiniest IoT devices, equipped with machine learning capabilities, can make quick decisions based on sensor data, enabling highly responsive and efficient systems.

This distributed intelligence is particularly crucial for applications that require real-time processing, such as autonomous vehicles, industrial automation, and smart healthcare. By processing data at the most appropriate layer of the computing continuum, we can ensure that decisions are made quickly and accurately, without relying on constant communication with a central server.

The migration of machine learning intelligence across the ecosystem also enables more personalized and context-aware experiences. By learning from user behavior and preferences at the edge, devices can adapt to individual needs without compromising privacy. This localized intelligence can then be aggregated and refined in the cloud, creating a feedback loop that continuously improves the overall system.

However, deploying machine learning systems across the computing continuum presents several challenges. Ensuring the interoperability and seamless integration of these systems requires standardized protocols and interfaces. Security and privacy concerns must also be addressed, as the distribution of intelligence across multiple layers increases the attack surface and the potential for data breaches.

Furthermore, the varying computational capabilities and energy constraints of devices at different layers of the computing continuum necessitate the development of efficient and adaptable machine learning models. Techniques such as model compression, federated learning, and transfer learning can help address these challenges, enabling the deployment of intelligence across a wide range of devices.

As we move towards the realization of Weiser's vision of ubiquitous computing, the development and deployment of machine learning systems across the entire ecosystem will be critical. By leveraging the strengths of each layer of the computing continuum, we can create an intelligent environment that seamlessly integrates with our daily lives, anticipating our needs and enhancing our experiences in ways that were once unimaginable. As we continue to push the boundaries of what's possible with distributed machine learning, we inch closer to a future where technology becomes an invisible but integral part of our world. @fig-applications-of-ml illustrates some common applications of AI around us.

![Common applications of Machine Learning. Source: [EDUCBA](https://www.educba.com/applications-of-machine-learning/)](images/png/mlapplications.png){#fig-applications-of-ml}

# 1. Introduction

## 1.1 What is a Machine Learning System?
- Definition and distinction from individual ML models
- Real-world examples of ML systems

## 1.2 Why Machine Learning Systems Matter
- Impact on industry and everyday life
- Challenges solved by ML systems

## 1.3 Anatomy of a Machine Learning System
- Key components:
  - Data pipeline
  - Model training
  - Inference
  - Monitoring
- How these components interact

## 1.4 From Model to System: The Big Picture
- Lifecycle of an ML system
- Introduction to MLOps

## 1.5 Challenges in Building ML Systems
- Scalability
- Reliability
- Maintainability

## 1.6 Case Studies
### A. A Day in the Life of a Large-Scale ML System
- Example: How a recommendation system works

### B. ML on the Edge: Embedded Systems
- Example: How a smart home device makes decisions

## 1.7 The Future of ML Systems
- Emerging trends
- Potential career paths in ML systems engineering

## 1.8 Chapter Summary and Book Overview
- Recap of key points
- Preview of upcoming chapters and how they relate to ML systems